\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{lmodern}        % https://github.com/rstudio/rticles/issues/343
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}

\title{Bootstrap Confidence Intervals with Differential Privacy}

\author{
    Marcel Neunhoeffer
   \\
    Department of Computer Science \\
    Boston University \\
  Boston, MA \\
  \texttt{\href{mailto:marceln@bu.edu}{\nolinkurl{marceln@bu.edu}}} \\
   \And
    Adam Smith
   \\
    Department of Computer Science \\
    Boston University \\
  Boston, MA \\
  \texttt{\href{mailto:ads22@bu.edu}{\nolinkurl{ads22@bu.edu}}} \\
  }

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}

% Pandoc citation processing
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc} % for calculating minipage widths
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\begin{document}
\maketitle

\def\tightlist{}


\begin{abstract}
Enter the text of your abstract here.
\end{abstract}

\keywords{
    Bootstrap
   \and
    Differential Privacy
   \and
    Statistical Inference
  }

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Here goes an introduction text

\hypertarget{our-proposed-method}{%
\section{Our proposed method}\label{our-proposed-method}}

\label{sec:method}

Instead of focusing on a single quantitiy of interest we produce
synthetic data in the form of a private (discretized) cumulative
distribution function (cdf). The private cdf is then used draw resamples
and apply the same mechanism on each of the resamples. This step does
not cost any additional privacy budget as it is post-processing the
private cdf. We then use the resulting distribution of cdfs calculate
confidence intervals for several statistics of interest (such as
quantiles, e.g.~the median, the mean, the probability of observing a
point in a particular region) and a confidence interval for the entire
cdf.

\hypertarget{related-work}{%
\section{Related Work}\label{related-work}}

\hypertarget{experiments}{%
\section{Experiments}\label{experiments}}

We evaluate the performance of our proposed method in a set of
experiments. First, we are interested in the validity of the generated
confidence intervals. Second, we evaluate how different settings of the
parameters in the algorithm (\(\epsilon\), \(B\), bounds, granularity)
affect the resulting confidence intervals. The results show that\ldots{}

\emph{Datasets.} To understand the behavior of our method under
different settings we look at several data sets. First, we look at data
sets where we have full control over the data generating process:

\begin{itemize}
\item data drawn from a standard normal distribution $\mathcal{N}(0, 1)$.
\item data drawn from a mixture of two normal distributions with equal weight $f(x) = \sum_{k=1}^K \lambda_k f_k(x)$, with $\lambda = (0.5, 0.5), f_1(x) = \mathcal{N}(-2, 0.25)$ and $f_2(x) = \mathcal{N}(2, 0.25)$. 
\item (different weights, different means, $\frac{1}{3}, \frac{2}{3}$)
\item lognormal distribution
\end{itemize}

Furthermore, we show results on real data and use the adult data set
from the UCI Machine Learning Repository (\cite{Dua2019}) that is
derived from 1994 census data. In particular we look at the age
variable.

Figure \ref{fig:fig1} summarizes the data sets. From each of the data
sets we draw samples \(\hat P\) of different sizes (50, 100, 500, 1000,
5000), to understand the behavior of our method at different sample
sizes.

\begin{figure}
\centering
\includegraphics{dp_bootstrap_inference_files/figure-latex/fig1-1.pdf}
\caption{Summary of the data sets}
\end{figure}

(Further potential real data sets: Census (ACS and/or decennial)) PUMS
data from IPUMS, Census business data)

\emph{Parameters.} In our algorithm we have several parameters that
influence the results. Most importantly we vary the privacy budget
\(\epsilon\) (0.1, 1, 10, Inf) and the number of bootstrap iterations
\(B\) (1000, increase for a couple of settings). Furthermore the lower
and upper bound of the cdf algorithm as well as the granularity
parameter play an important role and poorly set may bias results. For
the known data generating processes (normal, mixture) we set the lower
bound to \(-4\) and the upper bound to \(4\) and the granularity
parameter to \(0.01\). For the adult data we set the lower bound to
\(18\) and the upper bound to \(99\) with a granularity of \(0.1\).
(Other sets, how to choose them?)

\emph{Evaluation.} To understand the performance of our method we
repeatedly (100 times) apply the method to fresh samples \(\hat P\) from
the population data \(P\). For each sample \(\hat P\) we produce
confidence intervals and calculate the proportion of confidence
intervals that cover the true population value (empirical coverage).
Furthermore, we are interested in the length of the confidence intervals
(shorter intervals with coverage close to the nominal coverage are
better).

In the case of samples from the known data generating process we can
compare the resulting confidence intervals to the true population
values. For the adult data set (and other real data sets) we consider
the full data set as our ground truth and take simple random samples
from it to evaluate our proposed method. We consider the statistic of
interest calculated on the entire data set as our ground truth.

\emph{Statistics of interest.} Median, mean, some percentile
\(\frac{1}{3}\), entire cdf --\textgreater{} CI around it!

\hypertarget{results}{%
\section{Results}\label{results}}

(Ratio of length to non-private one, IQR of actual distribution)

(Results to record. Bootstrap distributions, Profiling of code,
Parallelization of code? )

(Combinations of parameters, other methods to get CIs, explain that
pivot doesn't work in some cases and show it. True value from
discretized data.)

\begin{figure}
\centering
\includegraphics{dp_bootstrap_inference_files/figure-latex/fig2-1.pdf}
\caption{Results for the normal distribution}
\end{figure}

\begin{figure}
\centering
\includegraphics{dp_bootstrap_inference_files/figure-latex/fig3-1.pdf}
\caption{Results for the mixture distribution}
\end{figure}

\begin{figure}
\centering
\includegraphics{dp_bootstrap_inference_files/figure-latex/fig4-1.pdf}
\caption{Results for the adult data}
\end{figure}

\hypertarget{notes}{%
\section{Notes}\label{notes}}

Different possibilities to get quantiles. So far we used the percentile
method.

The range and granularity need to be set properly (how?), otherwise
truncation and (too coarse) discretization can bias results.

\newpage

\hypertarget{instructions}{%
\section{Instructions}\label{instructions}}

You can use directly LaTeX command or Markdown text.

LaTeX command can be used to reference other section. See Section
\ref{sec:headings}. However, you can also use \textbf{bookdown}
extensions mechanism for this.

\hypertarget{headings-second-level}{%
\subsection{Headings: second level}\label{headings-second-level}}

You can use equation in blocks

\[
\xi _{ij}(t)=P(x_{t}=i,x_{t+1}=j|y,v,w;\theta)= {\frac {\alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}{\sum _{i=1}^{N} \sum _{j=1}^{N} \alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}}
\]

But also inline i.e \(z=x+y\)

\hypertarget{headings-third-level}{%
\subsubsection{Headings: third level}\label{headings-third-level}}

Another paragraph.

\hypertarget{examples-of-citations-figures-tables-references}{%
\section{Examples of citations, figures, tables,
references}\label{examples-of-citations-figures-tables-references}}

\label{sec:others}

You can insert references. Here is some text (Kour and Saabne 2014b,
2014a) and see Hadash et al. (2018).

The documentation for \verb+natbib+ may be found at

You can use custom blocks with LaTeX support from \textbf{rmarkdown} to
create environment.

\begin{center}
\url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf\%7D}

\end{center}

Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.

You can insert LaTeX environment directly too.

\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}

produces

\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}

\hypertarget{figures}{%
\subsection{Figures}\label{figures}}

You can insert figure using LaTeX directly.

See Figure \ref{fig:fig1}. Here is how you add footnotes. {[}\^{}Sample
of the first footnote.{]}

\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig3}
\end{figure}

But you can also do that using R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{dp_bootstrap_inference_files/figure-latex/fig5-1.pdf}
\caption{Another sample figure}
\end{figure}

You can use \textbf{bookdown} to allow references for Tables and
Figures.

\hypertarget{tables}{%
\subsection{Tables}\label{tables}}

Below we can see how to use tables.

See awesome Table\textasciitilde{}\ref{tab:table} which is written
directly in LaTeX in source Rmd file.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

You can also use R code for that.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\FunctionTok{head}\NormalTok{(mtcars), }\AttributeTok{caption =} \StringTok{"Head of mtcars table"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrrrrrrr@{}}
\caption{Head of mtcars table}\tabularnewline
\toprule
& mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb \\
\midrule
\endfirsthead
\toprule
& mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb \\
\midrule
\endhead
Mazda RX4 & 21.0 & 6 & 160 & 110 & 3.90 & 2.620 & 16.46 & 0 & 1 & 4 &
4 \\
Mazda RX4 Wag & 21.0 & 6 & 160 & 110 & 3.90 & 2.875 & 17.02 & 0 & 1 & 4
& 4 \\
Datsun 710 & 22.8 & 4 & 108 & 93 & 3.85 & 2.320 & 18.61 & 1 & 1 & 4 &
1 \\
Hornet 4 Drive & 21.4 & 6 & 258 & 110 & 3.08 & 3.215 & 19.44 & 1 & 0 & 3
& 1 \\
Hornet Sportabout & 18.7 & 8 & 360 & 175 & 3.15 & 3.440 & 17.02 & 0 & 0
& 3 & 2 \\
Valiant & 18.1 & 6 & 225 & 105 & 2.76 & 3.460 & 20.22 & 1 & 0 & 3 & 1 \\
\bottomrule
\end{longtable}

\hypertarget{lists}{%
\subsection{Lists}\label{lists}}

\begin{itemize}
\tightlist
\item
  Item 1
\item
  Item 2
\item
  Item 3
\end{itemize}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-hadash2018estimate}{}}%
Hadash, Guy, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and
Alon Jacovi. 2018. {``Estimate and Replace: A Novel Approach to
Integrating Deep Neural Networks with Existing Applications.''}
\emph{arXiv Preprint arXiv:1804.09028}.

\leavevmode\vadjust pre{\hypertarget{ref-kour2014fast}{}}%
Kour, George, and Raid Saabne. 2014a. {``Fast Classification of
Handwritten on-Line Arabic Characters.''} In \emph{Soft Computing and
Pattern Recognition (SoCPaR), 2014 6th International Conference of},
312--18. IEEE.

\leavevmode\vadjust pre{\hypertarget{ref-kour2014real}{}}%
---------. 2014b. {``Real-Time Segmentation of on-Line Handwritten
Arabic Script.''} In \emph{Frontiers in Handwriting Recognition (ICFHR),
2014 14th International Conference on}, 417--22. IEEE.

\end{CSLReferences}

\bibliographystyle{unsrt}
\bibliography{references.bib}


\end{document}
